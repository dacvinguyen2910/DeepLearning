{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ChunModelling - ANN"
      ],
      "metadata": {
        "id": "mgWDeSyt9xtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC5rKLdB9xA1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Input, Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/.../'"
      ],
      "metadata": {
        "id": "izMpFHXNCsva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "W4-YW979Cvtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "kX9zdqatCwda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Churn_Modelling.csv\")"
      ],
      "metadata": {
        "id": "Ghjruoqx95Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "41VlYJ7I97Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vuAbl3lhC8ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(by='Geography').count()"
      ],
      "metadata": {
        "id": "gzljsngXC--x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 3:13].values # inputs\n",
        "y = df.iloc[:, 13].values # output"
      ],
      "metadata": {
        "id": "ygdzJVUIDE7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exited = np.count_nonzero(y)\n",
        "exited"
      ],
      "metadata": {
        "id": "dIRzgbpCDGhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_exited = y.shape[0] - exited\n",
        "no_exited"
      ],
      "metadata": {
        "id": "HoMTe8fUDIfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import itemfreq\n",
        "# khach hang o lai/ra di\n",
        "itemfreq(y)"
      ],
      "metadata": {
        "id": "3XAugLHDDKFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical data\n",
        "# Encoding the Independent Variable\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "ct = ColumnTransformer([('encoder', OneHotEncoder(), [1])],\n",
        "remainder='passthrough')\n",
        "X = ct.fit_transform(X.tolist())\n",
        "# save 3 model nay pickle: labelencoder_X_1, labelencoder_X_2, ct\n",
        "# Save the Modle to file in the current working directory\n",
        "Pkl_Filename = \"Pickle_RL_Model.pkl\"\n",
        "with open(Pkl_Filename, 'wb') as file:\n",
        "pickle.dump(Model, file)\n",
        "# Load the Model back from file\n",
        "with open(Pkl_Filename, 'rb') as file:\n",
        "model_load = pickle.load(file)"
      ],
      "metadata": {
        "id": "QwTp_qY_DKqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale truoc => split sau\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(X)\n",
        "X = sc.transform(X)\n",
        "import pickle\n",
        "scalerfile = 'sc.sav'\n",
        "pickle.dump(sc, open(scalerfile, 'wb'))"
      ],
      "metadata": {
        "id": "39bQTfrtDTTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 0)"
      ],
      "metadata": {
        "id": "pKDonlxXDYRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:5]"
      ],
      "metadata": {
        "id": "k0XpjdDrDbtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "id": "HTRQpD75DdcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model ANN"
      ],
      "metadata": {
        "id": "Bamztdk3DhIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "7XgRh_XADj67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intitialing the ANN\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "yqIMVKNEDfMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6, activation='relu', input_shape=(11,)))\n",
        "classifier.add(Dropout(rate=0.1))"
      ],
      "metadata": {
        "id": "ClCvh_4sDooq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Addding the second hidden layer\n",
        "# output of previous layers => input of the next layers\n",
        "classifier.add(Dense(units = 6,\n",
        "                      activation='relu'))\n",
        "classifier.add(Dropout(rate=0.1))"
      ],
      "metadata": {
        "id": "3O1rpYr1DrMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1,\n",
        "                    activation='sigmoid')) # like logistic regression"
      ],
      "metadata": {
        "id": "HAEF7WN3D3Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling ANN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CC1kdwqLD6XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "id": "77FjEAjgD87x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "L5K9ZzVyD-2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(classifier, to_file='ANN_model.png', show_shapes=True)\n",
        "Image(filename='ANN_model.png')"
      ],
      "metadata": {
        "id": "hL27iG-LECMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate params: fully connected: Param # = input * output +\n",
        "output\n",
        "\n",
        "dense_input: Input layer: shape(None, 11), Param #=0\n",
        "\n",
        "dense:Dense: shape(?, 6), Param # = input * output + output = 11 * 6 + 6 = 72\n",
        "\n",
        "dense_1:Dense: shape(?, 6), Param # = input * output + output = 6 * 6 + 6 = 42\n",
        "\n",
        "dense_2:Dense: shape(?, 6), Param # = input * output + output = 6 * 1 + 1 = 7"
      ],
      "metadata": {
        "id": "3OrriPYZEGFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting classifier to the Training set\n",
        "history = classifier.fit(X_train, y_train,\n",
        "                          epochs = 100,\n",
        "                          batch_size=64,\n",
        "                          validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "DwoJygCQEMFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting classifier to the Training set\n",
        "history = classifier.fit(X_train, y_train,\n",
        "epochs = 100,\n",
        "batch_size=64,\n",
        "validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "CofcSPblERQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('val Loss & val Accuracy')\n",
        "plt.ylabel('Values')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['val Loss', 'val Acc'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HEH1aG_TETdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UtYxqldmEV9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "2A8YMrvREZIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[:5]"
      ],
      "metadata": {
        "id": "jqPCb6XPEatJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred >= 0.5\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "PiCxrOZ5Echq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "L6FRIIOREeNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = (cm[0][0] + cm[1][1])/ (cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "SM7Mf8CZEewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "print(\"Accuracy:\", classifier.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "DBXPkA0cEhqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the result\n",
        "from tensorflow.keras.models import load_model\n",
        "# Creates a HDF5 file 'my_model.h5'\n",
        "classifier.save('ANN_model.h5')"
      ],
      "metadata": {
        "id": "r2n6qm46EjfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use our ANN model to predict if the customer with the following informations will leave the\n",
        "\n",
        "bank:\n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: 50000\n",
        "\n",
        "So should we say goodbye to that customer ?"
      ],
      "metadata": {
        "id": "MGam9z_REma6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_pred = classifier.predict(sc.transform(np.array([[0, 0, 600, 1, 40, 3, 60000,\n",
        "                                                        2, 1, 1, 50000]])))"
      ],
      "metadata": {
        "id": "XsF8EMDTEp8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pred = new_pred > 0.5\n",
        "new_pred"
      ],
      "metadata": {
        "id": "SQu7kWTJEt8B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}