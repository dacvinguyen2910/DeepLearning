{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GANs - MINST"
      ],
      "metadata": {
        "id": "Tsl42NnODPp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "id": "WT75Z5Dc_svX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/../'"
      ],
      "metadata": {
        "id": "PrdkAS5n_uSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-KIU-sPn87NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gEqXOMuT88gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Reshape, Dense, Dropout, Flatten, LeakyReLU\n",
        "from tensorflow.keras.layers import Convolution2D, UpSampling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import initializers"
      ],
      "metadata": {
        "id": "gMEO0b8qDXoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deterministic output.\n",
        "# Tired of seeing the same results every time? Remove the line below.\n",
        "np.random.seed(1000)\n",
        "# The results are a little better when the dimensionality of the random vector is reduced\n",
        "# The dimensionality has been left at 100 for consistency with other GAN implemen\n",
        "random_dim = 100"
      ],
      "metadata": {
        "id": "Ck2BzZxW89li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "X_train = X_train.reshape(60000, 784)"
      ],
      "metadata": {
        "id": "8zdRa3v19A1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for read data"
      ],
      "metadata": {
        "id": "mqxSZpqWDtnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_minst_data():\n",
        "  # load the data\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  # normalize our inputs to be in the range[-1, 1]\n",
        "  x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "  # convert x_train with a shape of (60000, 28, 28) to (60000, 784) so we have\n",
        "  # 784 columns per row\n",
        "  x_train = x_train.reshape(60000, 784)\n",
        "  return (x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "pzYhFlifDv0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You will use the Adam optimizer\n",
        "def get_optimizer():\n",
        "  return Adam(lr=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "KN2XMC5ND2Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator(optimizer):\n",
        "  generator = Sequential()\n",
        "  generator.add(Dense(256,\n",
        "                input_dim=random_dim,\n",
        "                kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "  generator.add(LeakyReLU(0.2)) #https://en.wikipedia.org/wiki/Rectifier_(neura\n",
        "  generator.add(Dense(512))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  generator.add(Dense(1024))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  generator.add(Dense(784, activation='tanh'))\n",
        "  generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "  return generator"
      ],
      "metadata": {
        "id": "7n4AG2urD3EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator(optimizer):\n",
        "  discriminator = Sequential()\n",
        "  discriminator.add(Dense(1024,\n",
        "  input_dim=784,\n",
        "  kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  discriminator.add(Dense(512))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  discriminator.add(Dense(256))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  discriminator.add(Dense(1, activation='sigmoid'))\n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "  return discriminator"
      ],
      "metadata": {
        "id": "MYOoHUpWEC6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gan_network(discriminator, random_dim, generator, optimizer):\n",
        "  # We initially set trainable to False\n",
        "  # since we only want to train either the generator or discriminator at a time\n",
        "  discriminator.trainable = False\n",
        "  # gan input (noise) will be 100-dimensional vectors\n",
        "  gan_input = Input(shape=(random_dim,))\n",
        "  # the output of the generator (an image)\n",
        "  x = generator(gan_input)\n",
        "  # get the output of the discriminator (probability if the image is real or no\n",
        "  gan_output = discriminator(x)\n",
        "  gan = Model(inputs=gan_input, outputs=gan_output)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "  return gan"
      ],
      "metadata": {
        "id": "HvecgA4TEJSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a wall of generated MNIST images\n",
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10,10)):\n",
        "  noise = np.random.normal(0, 1, size=[examples, random_dim])\n",
        "  generated_images = generator.predict(noise)\n",
        "  generated_images = generated_images.reshape(examples, 28, 28)\n",
        "  plt.figure(figsize=figsize)\n",
        "  for i in range(generated_images.shape[0]):\n",
        "    plt.subplot(dim[0], dim[1], i+1)\n",
        "    plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "pIqLAyYbEO0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs=1, batch_size=128):\n",
        "  # Get the training and testing data\n",
        "  x_train, y_train, x_test, y_test = load_minst_data()\n",
        "  # Split the training data into batches of size 128\n",
        "  batch_count = x_train.shape[0] / batch_size\n",
        "  # Build our GAN netowrk\n",
        "  adam = get_optimizer()\n",
        "  generator = get_generator(adam)\n",
        "  discriminator = get_discriminator(adam)\n",
        "  gan = get_gan_network(discriminator, random_dim, generator, adam)\n",
        "  for e in range(1, epochs+1):\n",
        "    print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "    #process bar: https://tqdm.github.io/\n",
        "    for _ in tqdm(range(int(batch_count))):\n",
        "      # Get a random set of input noise and images\n",
        "      noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "      image_batch = x_train[np.random.randint(0, x_train.shape[0], size=bat\n",
        "      # Generate fake MNIST images\n",
        "      generated_images = generator.predict(noise)\n",
        "      X = np.concatenate([image_batch, generated_images])\n",
        "      # Labels for generated and real data\n",
        "      y_dis = np.zeros(2*batch_size)\n",
        "      # One-sided label smoothing\n",
        "      y_dis[:batch_size] = 0.9\n",
        "      # Train discriminator\n",
        "      discriminator.trainable = True\n",
        "      discriminator.train_on_batch(X, y_dis)\n",
        "      # Train generator\n",
        "      noise = np.random.normal(0, 1, size=[batch_size, random_dim])\n",
        "      y_gen = np.ones(batch_size)\n",
        "      discriminator.trainable = False\n",
        "      gan.train_on_batch(noise, y_gen)\n",
        "  if e == 1 or e % 20 == 0:\n",
        "    plot_generated_images(e, generator)\n",
        "# print into file: # save_generated_images(e, generator)"
      ],
      "metadata": {
        "id": "9cc2jEvyEayp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(200, 128) # chay epoch = 200, batch = 128"
      ],
      "metadata": {
        "id": "uE9OOE6eFBBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In progress bar\n",
        "from tqdm import tqdm\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "SAa2FiwGFCbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = tqdm(total=100)\n",
        "for i in range(10):\n",
        "  sleep(0.1)\n",
        "  pbar.update(10)\n",
        "pbar.close()"
      ],
      "metadata": {
        "id": "g77R95x3FEX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}