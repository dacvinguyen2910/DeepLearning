{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Air Pollution Forecasting - Many To One - RNN LSTM"
      ],
      "metadata": {
        "id": "Ejz52Oe5B--d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use this data and frame a forecasting problem where, given the\n",
        "pollution for prior hours, we forecast the pollution at the next hour"
      ],
      "metadata": {
        "id": "wx0Fm8IdCEiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGuDPtuEB-WL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "metadata": {
        "id": "rN9a1x4OCHJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/../'"
      ],
      "metadata": {
        "id": "P17c5g55CLOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM for air pollution problem with regression framing\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "rUlBRU2PCOCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('pollution_new_1.csv', index_col= 0)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "wt5bXInDF7k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "-ln8mWaDF8kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "k6ltoOIsGAf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = dataset.values\n",
        "# specify columns to plot\n",
        "groups = [0, 1, 2, 3, 5, 6, 7] # vì cột 4 là cột kiểu chuỗi\n",
        "i = 1\n",
        "# plot each column\n",
        "plt.figure(figsize=(20,20))\n",
        "for group in groups:\n",
        "  plt.subplot(len(groups), 1, i)\n",
        "  plt.plot(values[:, group])\n",
        "  plt.title(dataset.columns[group], y=0.5, loc='right')\n",
        "  i += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b4dqIwdPGCc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "  n_vars = 1 if type(data) is list else data.shape[1]\n",
        "  df = pd.DataFrame(data)\n",
        "  cols, names = list(), list()\n",
        "  # input sequence (t-n, ... t-1)\n",
        "  for i in range(n_in, 0, -1):\n",
        "    cols.append(df.shift(i))\n",
        "    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "  # forecast sequence (t, t+1, ... t+n)\n",
        "  for i in range(0, n_out):\n",
        "    cols.append(df.shift(-i))\n",
        "    if i == 0:\n",
        "      names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "    else:\n",
        "      names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "  # put it all together\n",
        "  agg = pd.concat(cols, axis=1)\n",
        "  agg.columns = names\n",
        "  # drop rows with NaN values\n",
        "  if dropnan:\n",
        "    agg.dropna(inplace=True) # kết quả sau khi drop gán luôn vào agg\n",
        "  return agg"
      ],
      "metadata": {
        "id": "KF3NTxvMGIjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load dataset\n",
        "values = dataset.values"
      ],
      "metadata": {
        "id": "FZKtd2Z3GzGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load dataset\n",
        "values = dataset.values\n",
        "# integer encode direction\n",
        "# convert string to int\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(values[:,4])\n",
        "values[:,4] = encoder.transform(values[:,4])\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit(values)\n",
        "scaled = scaler.transform(values)\n",
        "print(\"Frame as Series:\")\n",
        "print(scaled[:5])"
      ],
      "metadata": {
        "id": "h5PBXUSUG05e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frame as supervised learning\n",
        "reframed = series_to_supervised(scaled, 1, 1)\n",
        "print(\"Frame as supervised learning:\")\n",
        "print(reframed.head())\n",
        "# predict only var1(t), var2(t) not predicted =>drop\n",
        "# drop columns we don't want to predict\n",
        "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
        "print(\"Frame will use:\")\n",
        "print(reframed.head())"
      ],
      "metadata": {
        "id": "ubOzJVpuH1vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "n_train_hours = 365 * 24 * 4 # vì dữ liệu theo giờ (lấy 4 năm đầu train)\n",
        "train = values[:n_train_hours, :]\n",
        "# the left is used for Test\n",
        "test = values[n_train_hours:, :]\n",
        "# split into input and outputs (first col,last col)\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "print(\"Before reshape:\")\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "print(\"After reshape:\")\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "LbWVKNp8HdpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM"
      ],
      "metadata": {
        "id": "ANZIwUPwIcMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(train_X.shape[1], train_X.shape[2]))) # 1 sample has 8 featur\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "# fit network\n",
        "history = model.fit(train_X, train_y,\n",
        "                    epochs=50,\n",
        "                    batch_size=72,\n",
        "                    validation_data=(test_X, test_y),\n",
        "                    verbose=2\n",
        "                    )"
      ],
      "metadata": {
        "id": "i_g_8QsXIgJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "H-cYf5kSI4iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to calculate Params\n",
        "\n",
        "lstm (LSTM) = [(num_units + input_dim + 1) x num_units] x 4 = [(32 + 8 + 1) x 32] x 4 = 5248\n",
        "\n",
        "dense = ((current layer n x previous layer n) + bias) = 1 x 32 + 1 = 33"
      ],
      "metadata": {
        "id": "gHbGNhPBI8MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lQ1qWiyVJCzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X.shape"
      ],
      "metadata": {
        "id": "MpQByUraJE5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "c-dLIM_oJGvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_scaling(y, X, s):\n",
        "  # invert scaling for forecast\n",
        "  inv_y = np.concatenate((y, X[:, 1:]), axis=1)\n",
        "  print(s, \"shape:\", inv_y.shape)\n",
        "  inv_y = scaler.inverse_transform(inv_y)\n",
        "  print(s, inv_y.shape)\n",
        "  # trả lại hình dạng ban đầu\n",
        "  inv_y = inv_y[:,0]\n",
        "  return inv_y"
      ],
      "metadata": {
        "id": "Ll6nvIhkJIdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction\n",
        "yhat = model.predict(test_X)\n",
        "print(\"Test_x_shape:\", test_X.shape)\n",
        "test_X_now = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "print(\"Test_x_now_shape:\", test_X_now.shape)"
      ],
      "metadata": {
        "id": "kfX5EBc-JQGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invert scaling for forecast\n",
        "inv_yhat = np.concatenate((yhat, test_X_now[:, 1:]), axis=1)\n",
        "print(\"inv_y_hat_shape:\", inv_yhat.shape)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "print(\"inv_yhat:\", inv_yhat.shape)\n",
        "# revert to origin\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "inv_yhat = invert_scaling(yhat, test_X_now, \"inv_yhat\")"
      ],
      "metadata": {
        "id": "-SqOjicxJQre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#invert scaling for actual\n",
        "inv_y = np.concatenate((test_y, test_X_now[:, 1:]), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "inv_y = invert_scaling(test_y, test_X_now, \"inv_y\")"
      ],
      "metadata": {
        "id": "h28VzU9DJZr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate RMSE\n",
        "rmse = math.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test MAE: %.3f' % mae)"
      ],
      "metadata": {
        "id": "XG2EjxfyJfiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(inv_y - inv_yhat, label='Diff between y_test and y_test_hat')\n",
        "plt.legend(title=\"Notes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6VizqVT3JkgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a prediction of y\n",
        "y_train_hat = model.predict(train_X)\n",
        "train_X_now = train_X.reshape((train_X.shape[0], train_X.shape[2]))"
      ],
      "metadata": {
        "id": "X6doI5dfJsSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#invert scaling for forecast\n",
        "inv_y_train_hat = np.concatenate((y_train_hat, train_X_now[:, 1:]), axis=1)\n",
        "inv_y_train_hat = scaler.inverse_transform(inv_y_train_hat)\n",
        "inv_y_train_hat = inv_y_train_hat[:,0]"
      ],
      "metadata": {
        "id": "tnaSPs1pJtJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_y_train_hat = invert_scaling(y_train_hat, train_X_now, \"inv_y_train_hat\")"
      ],
      "metadata": {
        "id": "i3U8KzSZJyB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot baseline and predictions\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(test_y, label='Test Real Data', color='red')\n",
        "plt.plot(yhat, label='Test Prediction', color='green')\n",
        "plt.legend(title=\"Notes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xihKysT_Jzrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot baseline and predictions\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(test_y, label='Test Real Data', color='red')\n",
        "plt.plot(yhat, label='Test Prediction', color='green')\n",
        "plt.legend(title=\"Notes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WVScbUpdJ1gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Val_loss train')\n",
        "model.evaluate(train_X, train_y)"
      ],
      "metadata": {
        "id": "GJ96mnoWJ40e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Val_loss test')\n",
        "model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "id": "Sp882BeIJ6me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make new prediction"
      ],
      "metadata": {
        "id": "ICRZUP3DJ8G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_new = pd.read_csv('pollution_new_predict.csv', index_col= 0)\n",
        "dataset_new.head()"
      ],
      "metadata": {
        "id": "ZZjscICnJ8lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values_new = dataset_new.values\n",
        "values_new"
      ],
      "metadata": {
        "id": "t6yW02cVJ_km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values_new[:,4] = encoder.transform(values_new[:,4])\n",
        "# ensure all data is float\n",
        "values_new = values_new.astype('float32')\n",
        "values_new.size"
      ],
      "metadata": {
        "id": "h8G-tBDFKBXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(values_new)"
      ],
      "metadata": {
        "id": "Oh6DUdxgKBx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_new = scaler.transform(values_new)\n",
        "print(scaled_new)"
      ],
      "metadata": {
        "id": "DFLOHkuOKD6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dataframe as supervised learning\n",
        "reframed_new = series_to_supervised(scaled_new, 1, 1)\n",
        "reframed_new.drop(reframed_new.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
        "print(reframed_new.head())"
      ],
      "metadata": {
        "id": "BHMDMKdVKG62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reframed_new.shape"
      ],
      "metadata": {
        "id": "NEvvSZQUKIjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values_new = reframed_new.values\n",
        "# split into input and outputs\n",
        "new_pre = values_new[:, :-1]\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "new_pre = new_pre.reshape((new_pre.shape[0], 1, new_pre.shape[1]))\n",
        "print(new_pre.shape)"
      ],
      "metadata": {
        "id": "_Mq_nApvKKIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_new_pre = model.predict(new_pre)\n",
        "yhat_new_pre"
      ],
      "metadata": {
        "id": "LeBqbX0DKL4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invert scaling for actual\n",
        "yhat_new_pre = yhat_new_pre.reshape((len(yhat_new_pre), 1))\n",
        "new_pre_now = new_pre.reshape((new_pre.shape[0], new_pre.shape[2]))"
      ],
      "metadata": {
        "id": "zDsScscxKNlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_new_pre = np.concatenate((yhat_new_pre, new_pre_now[:, 1:]), axis=1)\n",
        "yhat_new_pre = scaler.inverse_transform(yhat_new_pre)\n",
        "yhat_new_pre = yhat_new_pre[:,0]\n",
        "yhat_new_pre = invert_scaling(yhat_new_pre, new_pre_now, \"yhat_new_pre\")\n",
        "yhat_new_pre"
      ],
      "metadata": {
        "id": "z0-fKQgPKP02"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}