{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Identifying spam in popular YouTube videos\n",
        "comments with LSTM - Keras"
      ],
      "metadata": {
        "id": "8j747VuGut8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-nbStJAur5W"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/My Drive/LDS8_DeepLearning/Practice/Chapter7_NLP/'"
      ],
      "metadata": {
        "id": "opA_N7E5uzA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "_VYyEajOu18D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embe\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pU2GbQfru3p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df_list = []\n",
        "comments_file = ['data/Youtube01-Psy.csv',\n",
        "                  'data/Youtube02-KatyPerry.csv',\n",
        "                  'data/Youtube03-LMFAO.csv',\n",
        "                  'data/Youtube04-Eminem.csv',\n",
        "                  'data/Youtube05-Shakira.csv']\n",
        "for f in comments_file:\n",
        "  print(f)\n",
        "  df = pd.read_csv(f,header=0)\n",
        "  comments_df_list.append(df)\n",
        "comments_df = pd.concat(comments_df_list)\n",
        "# comments_df = comments_df.sample(frac=1.0)\n",
        "print(comments_df.shape)\n",
        "comments_df.head(5)"
      ],
      "metadata": {
        "id": "v7E3uSUBu5fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.columns"
      ],
      "metadata": {
        "id": "6ZINVc09vBf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/kredy10/simple-lstm-for-text-classification\n",
        "df = comments_df.drop(['COMMENT_ID', 'AUTHOR', 'DATE'], axis = 1)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "2d9xp274vEET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['V1'] = df['CLASS'].map(lambda x: 'ham' if x==0 else 'spam')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "d0Kh1rFLvGBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "2O5jED4ivHsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.CLASS)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Number of ham-0 and spam-1 content')"
      ],
      "metadata": {
        "id": "Q9wbWkxhvJYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.CONTENT # input\n",
        "Y = df.CLASS # output"
      ],
      "metadata": {
        "id": "BbsPWAFFvK5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3)"
      ],
      "metadata": {
        "id": "gsXJL9zxvMbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the data\n",
        "\n",
        "Tokenize the data and convert the text to sequences.\n",
        "\n",
        "Add padding to ensure that all the sequences have the same shape.\n",
        "\n",
        "There are many ways of taking the max_len and here an arbitrary length of 150 is chosen."
      ],
      "metadata": {
        "id": "YRqKYpN8vOD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train) # 3 => 3 word IDs, 5 => 5 wordIDs\n",
        "sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)"
      ],
      "metadata": {
        "id": "Yra_X79NvQTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[:2])"
      ],
      "metadata": {
        "id": "lA_4k0eHvX5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_matrix[:2]"
      ],
      "metadata": {
        "id": "3YVMm1nmvZd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN"
      ],
      "metadata": {
        "id": "xKBFsoYsvbO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN():\n",
        "  inputs = Input(name='inputs',shape=[max_len])\n",
        "  layer = Embedding(max_words, 50, input_length=max_len)(inputs)\n",
        "  layer = LSTM(64)(layer)\n",
        "  layer = Dense(256,name='FC1')(layer)\n",
        "  layer = Activation('relu')(layer)\n",
        "  layer = Dropout(0.5)(layer)\n",
        "  layer = Dense(1,name='out_layer')(layer)\n",
        "  layer = Activation('sigmoid')(layer)\n",
        "  model = Model(inputs=inputs,outputs=layer)\n",
        "  return model"
      ],
      "metadata": {
        "id": "bfhMGQHZvcSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = RNN()\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 50))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "l8N335CCvilk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = RNN()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "20FHGF_JvkRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "4pt3XAu5vnLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CALCULATE embedling layer: input * output = 1000*50 = 50000\n",
        "\n",
        "lstm layer = [(num_unit + inputdims)num_unit]4 = (64+50+1)644 = 29440\n",
        "\n",
        "dense layer = 64*256 + 256 = 16640\n",
        "\n",
        "dropout = 0\n",
        "\n",
        "dense output layer = 256*1 + 1 = 257\n"
      ],
      "metadata": {
        "id": "XKLhI88twIf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "-etUPy7Nvpab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='LSTM_model.png', show_shapes=True)\n",
        "Image(filename='LSTM_model.png')"
      ],
      "metadata": {
        "id": "T3-azAWjvrPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3xJoFfJgvtXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(sequences_matrix,Y_train, # train\n",
        "                    batch_size=128,\n",
        "                    epochs=50,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=5)])"
      ],
      "metadata": {
        "id": "82WQo7oTvvsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "sQcXUKoov3Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accr = model.evaluate(test_sequences_matrix,Y_test)"
      ],
      "metadata": {
        "id": "Q2BrX2-Qv4bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "id": "UQon2unev5Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the result\n",
        "from tensorflow.keras.models import load_model\n",
        "# Creates a HDF5 file 'my_model.h5'\n",
        "model.save('LSTM_spam_model.h5')"
      ],
      "metadata": {
        "id": "qjatE4G_v78L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make new predictions"
      ],
      "metadata": {
        "id": "unxegVRhv9xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_test)"
      ],
      "metadata": {
        "id": "YUSyk_rlv-cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences_new = tok.texts_to_sequences(X_new)\n",
        "test_sequences_matrix_new = sequence.pad_sequences(test_sequences_new,maxlen=max_len)"
      ],
      "metadata": {
        "id": "wsRetzGNwgIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new"
      ],
      "metadata": {
        "id": "SQ3IL7V_w-fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences_matrix_new"
      ],
      "metadata": {
        "id": "Zgp0Y3OMxA-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_sequences_matrix_new)"
      ],
      "metadata": {
        "id": "VDwC-cbHxEMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}